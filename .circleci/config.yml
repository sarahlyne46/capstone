version: 2.1

orbs:
  aws-cli: circleci/aws-cli@2.0.3
  aws-eks: circleci/aws-eks@0.2.3
  kubernetes: circleci/kubernetes@0.12.0  
#  slack: circleci/slack@4.2.1https://github.com/sarahlyne46/capstone/tree/sarahlyne46-cap1-ubuntu

parameters:
  DOCKER_PATH:
    type: string
    default: "sarahlyne46/capstone-test"
  DOCKER_IMAGE_NAME:
    type: string
    default: "2211-new"
  ENV_NAME:
    type: string
    default: "capstone-2211"
  KEY_PAIR:
    type: string
    default: "capstone"

    
    
commands:
  delete-environment:
    description: Destroy cloudformation stacks given a workflow ID.
    steps:
      - run:
          name: Destroy environments
          command: |
            # Delete Servers stack
            aws cloudformation delete-stack --stack-name {ENV_NAME}-servers --region us-west-2
            # Delete Nodegroup stack
            aws cloudformation delete-stack --stack-name {ENV_NAME}-nodegroup --region us-west-2
            # Delete Cluster stack
            aws cloudformation delete-stack --stack-name {ENV_NAME}-cluster --region us-west-2
            # Delete Network stack
            aws cloudformation delete-stack --stack-name {ENV_NAME}-network --region us-west-2     
            
            
jobs:
  build:
    docker:
      - image: python:3.7.3-stretch

    steps:
      - checkout
      # Download and cache dependencies
      - restore_cache:
          keys:
            - v1-dependencies-{{ checksum "requirements.txt" }}
            # fallback to using the latest cache if no exact match is found
            - v1-dependencies-

      - run:
          name: install dependencies
          command: |
            python3 -m venv venv
            . venv/bin/activate
            make install
      - run:
          name: Install hadolint
          command: |
            wget -O /bin/hadolint https://github.com/hadolint/hadolint/releases/download/v1.16.3/hadolint-Linux-x86_64 && chmod +x /bin/hadolint
      - run:
          name: run lint
          command: |
            . venv/bin/activate
            make lint   
      - save_cache:
          paths:
            - ./venv
          key: v1-dependencies-{{ checksum "requirements.txt" }}

  upload-docker:
    docker:
      - image: circleci/golang:1.15
        auth:
          username: $DOCKERHUB_USERNAME
          password: $DOCKERHUB_PASSWORD

    working_directory: ~/repo

    steps:
      - checkout
      
      - setup_remote_docker:
          version: 19.03.13

      - run:
          name: Build docker container
          command: |
          
            docker build -t $DOCKER_IMAGE_NAME .
            docker image ls
      - run:
          name: Test docker container
          command: |
            docker run -d --rm --name testapp -p 8081:8080 $DOCKER_IMAGE_NAME
            sleep 5
            docker container ls
            export URL="http://http://172.17.0.2:8081"
            export response=$(curl -s $URL)
            echo "This is the response from local host $response"
            sleep 10
            docker stop testapp
      
      - run:
          name: Upload docker container
          command: |
            echo "Docker ID and Image: $DOCKER_IMAGE_NAME"
            docker login -u="$DOCKERHUB_USERNAME" -p="$DOCKERHUB_PASSWORD"
            docker tag $DOCKER_IMAGE_NAME $DOCKER_PATH:$DOCKER_IMAGE_NAME
            docker push $DOCKER_PATH:$DOCKER_IMAGE_NAME
 
            
  create-infrastructure:
    executor: aws-eks/python3
    parameters:
      cluster-name:
        description: | 
          Name of the EKS cluster
        type: string

    steps:
      - checkout
      
      - aws-eks/install-aws-iam-authenticator:
          release-tag: ''
      - run:
          name: Install the eksctl tool
          command: |
            if which eksctl > /dev/null; then
            echo "eksctl is already installed"
            exit 0
            fi
            mkdir -p eksctl_download
            curl --location --retry 5 "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C eksctl_download
            chmod +x eksctl_download/eksctl
            SUDO=""
            if [ $(id -u) -ne 0 ] && which sudo > /dev/null ; then
            SUDO="sudo"
            fi
            $SUDO mv eksctl_download/eksctl /usr/local/bin/
            rmdir eksctl_download
      - aws-eks/create-cluster:
          cluster-name: << parameters.cluster-name >>
          skip-kubectl-install: false
          verbose: 3
          node-type: t2.small
          nodes-max: 2
          ssh-access: false
          ssh-public-key: ''         
            
            
            
  check-cluster:
    executor: aws-eks/python3
    parameters:
      cluster-name:
        description: |
          Name of the EKS cluster
        type: string
    steps:
      - kubernetes/install
      - aws-eks/update-kubeconfig-with-authenticator:
          cluster-name: << parameters.cluster-name >>
      - run:
          name: Kube cluster
          command: |
            kubectl get services
            
            
  deploy-code:
    executor: aws-eks/python3
    parameters:
      cluster-name:
        description: |
          Name of the EKS cluster
        type: string

    steps:
      - checkout
      - aws-eks/update-kubeconfig-with-authenticator:
          cluster-name: << parameters.cluster-name >>
          install-kubectl: true
      - kubernetes/create-or-update-resource:
          get-rollout-status: true
          resource-file-path: deployment.yml
          resource-name: deployment/capstone-project-deployment            

  test-deployment:
    executor: aws-eks/python3
    parameters:
      cluster-name:
        description: |
          Name of the EKS cluster
        type: string
    steps:
      - kubernetes/install
      - aws-eks/update-kubeconfig-with-authenticator:
          cluster-name: << parameters.cluster-name >>
      - run:
          name: Kube cluster
          command: |
            kubectl get svc
            kubectl get nodes
            kubectl get deployment
            


workflows:
  default:
    jobs:
       - build
       - upload-docker:
           requires: [build]
#       - create-infrastructure:
#           cluster-name: sarah-2211
#           requires: [upload-docker]
       - check-cluster:
           cluster-name: sarah-2211
           requires: [upload-docker]
       - deploy-code:
           cluster-name: sarah-2211
           requires: [check-cluster]
       - test-deployment:
           cluster-name: sarah-2211
           requires: [deploy-code]
#       - aws-eks/update-container-image:
#           cluster-name: siva-capstone
#           container-image-updates: 'siva-capstone-deployment=dockerbeginnersiva/project6:4.0'
#           get-rollout-status: true
#           record: true
#           requires: [test-deployment]
#           resource-name: deployment/capstone-project-deployment        

#      - aws-eks/delete-cluster:
#          cluster-name: sarah-2211
#          requires:
#            - aws-eks/update-container-image           
#       - deploy-infrastructure:
#           requires: [upload-docker]       
#           filters:
#             branches:
#               only: [main]           
#       - configure-infrastructure:
#           requires: [deploy-infrastructure]
#           filters:
#             branches:
#               only: [main]            
#       - configure-cluster:
#           requires: [configure-infrastructure]
#           filters:
#             branches:
#               only: [main]      
#       - deploy-code:
#           requires: [configure-cluster]
#           filters:
#             branches:
#               only: [main]